<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>tfjs - face deta</title>

  <script src="./lib/js/tfjs.js"></script>
  <script src="./lib/js/blazeface.js"></script>
</head>
<body>

  <input type="checkbox" name="" id="loveInEyes" checked>æƒ…äººè¥¿æ–½
  <input type="checkbox" name="" id="wearMask">é˜²ç–«è¾¾äºº
  <input type="checkbox" name="" id="redMouse">çƒˆç„°çº¢å”‡
  <input type="checkbox" name="" id="smile">èœœæ±å¾®ç¬‘

  <div id="container">
    <video src="" autoplay playsinline muted onloadeddata="onLoad()" onloadedmetadata="main()"></video>
  </div>

  <script>

    let model = null;

    const canvas = document.createElement('canvas');
    const context = canvas.getContext('2d');
    const input = document.querySelector('video');
    document.querySelector('#container').appendChild(canvas);

    async function main() {
      const currentTime = Date.now();
      if (model) {
        // Pass in an image or video to the model. The model returns an array of
        // bounding boxes, probabilities, and landmarks, one for each detected face.
        const returnTensors = false; // Pass in `true` to get tensors back, rather than values.
        // é€šå¸¸æˆ‘ä»¬ä¼šæŠŠè¿™ä¸€äº›è®¡ç®—æ”¾åˆ° worker ä¸­ï¼Œä½†æ˜¯ç”±äº work ä¸èƒ½ä¼ é€’ DOM èŠ‚ç‚¹
        const predictions = await model.estimateFaces(input, returnTensors);
        context.clearRect(0, 0, canvas.width, canvas.height);
        context.drawImage(input, 0, 0);
        // Pass in an image or video to the model. The model returns an array of
        // bounding boxes, probabilities, and landmarks, one for each detected face.
        if (predictions.length > 0) {
          console.log('predictions  ', predictions);
          /*
          `predictions` is an array of objects describing each detected face, for example:

          [
            {
              topLeft: [232.28, 145.26],
              bottomRight: [449.75, 308.36],
              probability: [0.998],
              landmarks: [
                [295.13, 177.64], // right eye
                [382.32, 175.56], // left eye
                [341.18, 205.03], // nose
                [345.12, 250.61], // mouth
                [252.76, 211.37], // right ear
                [431.20, 204.93] // left ear
              ]
            }
          ]
          */

          for (let i = 0; i < predictions.length; i++) {
            const start = predictions[i].topLeft;
            const end = predictions[i].bottomRight;
            const size = [end[0] - start[0], end[1] - start[1]];

            const rightEyeP = predictions[i].landmarks[0];
            const leftEyeP = predictions[i].landmarks[1];
            const noseP = predictions[i].landmarks[2];
            const mouseP = predictions[i].landmarks[3];
            const rightEarP = predictions[i].landmarks[4];
            const leftEarP = predictions[i].landmarks[5];

            // Render a rectangle over each detected face.
            // context.fillRect(start[0], start[1], size[0], size[1]);

            // è¦†ç›–
            // const fontSize = end[1] - start[1];
            // context.font = `${fontSize}px/${fontSize}px serif`
            // context.fillText('ğŸ˜—', start[0], start[1] + fontSize);

            // å§šæ˜è¿·ä¹‹å¾®ç¬‘
            if (smile.checked) {
              const image = new Image();
              image.src = "./assets/images/yaoMingSmile.jpeg";
              image.onload = function() {
                const top = noseP[1] - start[1];
                const left = start[0];
                // å˜´å·´ä¸ºä¸­å¿ƒç‚¹ï¼Œä¸€åŠä¸Šé¢ä¸€åŠä¸‹é¢
                context.drawImage(image, start[0], start[1], size[0], size[1]);
              }
            }

            // çœ¼ç›æ·»åŠ çˆ±å¿ƒ
            if (loveInEyes.checked) {
              const fontSize = rightEyeP[1] - start[1];
              context.font = `${fontSize}px/${fontSize}px serif`;
              context.fillStyle = 'red';
              context.fillText('â¤ï¸', rightEyeP[0] - fontSize / 2, rightEyeP[1]);
              context.fillText('â¤ï¸', leftEyeP[0] - fontSize / 2, leftEyeP[1]);
            }

            // æˆ´å£ç½©
            if (wearMask.checked) {
              const image = new Image();
              image.src = "./assets/images/mouthMask.png";
              image.onload = function() {
                const top = noseP[1] - start[1];
                const left = start[0];
                // å˜´å·´ä¸ºä¸­å¿ƒç‚¹ï¼Œä¸€åŠä¸Šé¢ä¸€åŠä¸‹é¢
                context.drawImage(image, mouseP[0] - size[0] / 2, mouseP[1] - size[1] / 2, size[0], size[1]);
              }
            }

            // åŠ ä¸ªçƒˆç„°çº¢å”‡
            if (redMouse.checked) {
              // å˜´å·´å¤§æ¦‚æ˜¯çœ¼ç›ä¹‹å‰çš„å®½åº¦
              const fontSize = Math.abs(rightEyeP[0] - leftEyeP[0]);
              context.font = `${fontSize}px/${fontSize}px serif`;
              context.fillStyle = 'red';
              context.fillText('ğŸ‘„', mouseP[0] - fontSize / 2, mouseP[1] + fontSize / 2);
            }
          }
        }
      }
      requestAnimationFrame(main)
    }

    async function start() {
      const localStream = await navigator.mediaDevices.getUserMedia({video: {}});
      input.srcObject = localStream;
    }

    async function onLoad() {
      canvas.width = input.videoWidth;
      canvas.height = input.videoHeight;

      // Load the model.
      model = await blazeface.load();
    }

    start();
    // main();
  </script>
</body>
</html>